{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import osgeo\n",
    "from osgeo import gdal, ogr, osr\n",
    "from gdalconst import GA_ReadOnly\n",
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "\n",
    "#my things\n",
    "from mosaic_rasters_functions import raster_mask_to_shapefile, clip_by_utm_zone\n",
    "\n",
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = list(range(7, 12)) #12 because python needs the + 1\n",
    "raster_locations = [os.path.join(\"..\", \"data\", \"non_overlapping_masks\", \"UTM\" + str(zone) + \"S_vld_ext.dat\") for zone in zones]\n",
    "save_name = [\"UTM_\" + str(zone) + \"S_mask.shp\" for zone in zones]\n",
    "\n",
    "mask_inputs = [(raster_locations[i], save_name[i]) for i in range(0, len(raster_locations))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to generate shapefile masks\n",
      "12.141518592834473\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if __name__ == '__main__':\n",
    "    with Pool() as pool:\n",
    "        pool.starmap(raster_mask_to_shapefile, mask_inputs)\n",
    "end_time = time.time()\n",
    "print(\"Time to generate shapefile masks\")\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the extent of BC to merge the rasters together (currently not used due to time procesing times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_boundary = os.path.join(\"..\", \"data\", \"shapefiles\", \"bc_boundary.shp\")\n",
    "\n",
    "in_driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "data = in_driver.Open(bc_boundary, 0)\n",
    "layer = data.GetLayer()\n",
    "for feature in layer:\n",
    "    bc_extent = feature.GetGeometryRef().GetEnvelope()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BC Extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Layer's Extent\n",
    "inShapefile = bc_boundary\n",
    "inDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "inDataSource = inDriver.Open(inShapefile, 0)\n",
    "inLayer = inDataSource.GetLayer()\n",
    "extent = inLayer.GetExtent()\n",
    "\n",
    "# Create a Polygon from the extent tuple\n",
    "ring = ogr.Geometry(ogr.wkbLinearRing)\n",
    "ring.AddPoint(extent[0],extent[2])\n",
    "ring.AddPoint(extent[1], extent[2])\n",
    "ring.AddPoint(extent[1], extent[3])\n",
    "ring.AddPoint(extent[0], extent[3])\n",
    "ring.AddPoint(extent[0],extent[2])\n",
    "poly = ogr.Geometry(ogr.wkbPolygon)\n",
    "poly.AddGeometry(ring)\n",
    "\n",
    "# Save extent to a new Shapefile\n",
    "outShapefile = os.path.join(\"..\", \"data\", \"shapefiles\", \"bc_extent.shp\")\n",
    "outDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "\n",
    "# Remove output shapefile if it already exists\n",
    "if os.path.exists(outShapefile):\n",
    "    outDriver.DeleteDataSource(outShapefile)\n",
    "\n",
    "# Create the output shapefile\n",
    "outDataSource = outDriver.CreateDataSource(outShapefile)\n",
    "outLayer = outDataSource.CreateLayer(\"bc_extent\", geom_type=ogr.wkbPolygon)\n",
    "\n",
    "# Add an ID field\n",
    "idField = ogr.FieldDefn(\"id\", ogr.OFTInteger)\n",
    "outLayer.CreateField(idField)\n",
    "\n",
    "# Create the feature and set values\n",
    "featureDefn = outLayer.GetLayerDefn()\n",
    "feature = ogr.Feature(featureDefn)\n",
    "feature.SetGeometry(poly)\n",
    "feature.SetField(\"id\", 1)\n",
    "outLayer.CreateFeature(feature)\n",
    "feature = None\n",
    "\n",
    "# Save and close DataSource\n",
    "inDataSource = None\n",
    "outDataSource = None\n",
    "\n",
    "spatialRef = osr.SpatialReference()\n",
    "spatialRef.ImportFromEPSG(3005)\n",
    "\n",
    "spatialRef.MorphToESRI()\n",
    "file = open(os.path.join(\"..\", \"data\", \"shapefiles\", 'bc_extent.prj'), 'w')\n",
    "file.write(spatialRef.ExportToWkt())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BC Convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Layer\n",
    "inShapefile = bc_boundary\n",
    "inDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "inDataSource = inDriver.Open(inShapefile, 0)\n",
    "inLayer = inDataSource.GetLayer()\n",
    "\n",
    "# Collect all Geometry\n",
    "geomcol = ogr.Geometry(ogr.wkbGeometryCollection)\n",
    "for feature in inLayer:\n",
    "    geomcol.AddGeometry(feature.GetGeometryRef())\n",
    "\n",
    "# Calculate convex hull\n",
    "convexhull = geomcol.ConvexHull()\n",
    "\n",
    "# Save extent to a new Shapefile\n",
    "outShapefile = os.path.join(\"..\", \"data\", \"shapefiles\", \"bc_convex.shp\")\n",
    "outDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "\n",
    "# Remove output shapefile if it already exists\n",
    "if os.path.exists(outShapefile):\n",
    "    outDriver.DeleteDataSource(outShapefile)\n",
    "\n",
    "# Create the output shapefile\n",
    "outDataSource = outDriver.CreateDataSource(outShapefile)\n",
    "outLayer = outDataSource.CreateLayer(\"bc_convex\", geom_type=ogr.wkbPolygon)\n",
    "\n",
    "# Add an ID field\n",
    "idField = ogr.FieldDefn(\"id\", ogr.OFTInteger)\n",
    "outLayer.CreateField(idField)\n",
    "\n",
    "# Create the feature and set values\n",
    "featureDefn = outLayer.GetLayerDefn()\n",
    "feature = ogr.Feature(featureDefn)\n",
    "feature.SetGeometry(convexhull)\n",
    "feature.SetField(\"id\", 1)\n",
    "outLayer.CreateFeature(feature)\n",
    "feature = None\n",
    "\n",
    "# Save and close DataSource\n",
    "inDataSource = None\n",
    "outDataSource = None\n",
    "\n",
    "spatialRef = osr.SpatialReference()\n",
    "spatialRef.ImportFromEPSG(3005)\n",
    "\n",
    "spatialRef.MorphToESRI()\n",
    "file = open(os.path.join(\"..\", \"data\", \"shapefiles\", 'bc_convex.prj'), 'w')\n",
    "file.write(spatialRef.ExportToWkt())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_variables = [\"loreys_height\", \"total_biomass\", \"percentage_first_returns_above_2m\"]\n",
    "vlce_variables = [\"vlce\"]\n",
    "utm_variables = [\"Logic_Rules_Change_Attribution\"]\n",
    "\n",
    "structure_vlce_years = list(range(1984, 2020))\n",
    "utm_years = list(range(1985, 2019))\n",
    "\n",
    "structure_years_variables = itertools.product(structure_variables, structure_vlce_years)\n",
    "vlce_years_variables = itertools.product(vlce_variables, structure_vlce_years)\n",
    "utm_years_variables = itertools.product(utm_variables, utm_years)\n",
    "\n",
    "years_variables = [item for item in vlce_years_variables] + [item for item in utm_years_variables] + [item for item in structure_years_variables]\n",
    "\n",
    "zones = list(range(7, 12)) #12 because python needs the + 1\n",
    "\n",
    "#print(years_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate mask polygons from Txomin's raster masks\n",
    "\n",
    "Function from Nick Leach with minor edits\n",
    "\n",
    "Throws a depreciated warnings due to the CRS that I can't figure out how to fix, but as of March 2021, it still works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    }
   ],
   "source": [
    "num_total = len(years_variables)\n",
    "print(num_total)\n",
    "num_done = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: Clips rasters to the valid zonal pixels based on Txomin's mask.\n",
    "\n",
    "Then: Merges clipped rasters into a BC wide raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "mask = os.path.join(\"..\", \"data\", \"shapefiles\", \"bc_convex.shp\")\n",
    "\n",
    "for item in years_variables[num_done - 1:]:\n",
    "    variable = item[0]\n",
    "    year = item[1]\n",
    "    print(str(num_done), \"/\", str(num_total))\n",
    "    print(year, variable)\n",
    "    \n",
    "    if variable in structure_variables:\n",
    "        rasters = [os.path.join(\"H:\\\\\", \"Structure\", \"UTM_\" + str(zone) + \"S\", variable, \"UTM_\" + str(zone) + \"S_\" + variable + \"_\" + str(year) + \".dat\") for zone in zones]\n",
    "        nodata_value = 0\n",
    "    \n",
    "    if variable in vlce_variables:\n",
    "        rasters = [os.path.join(\"H:\\\\\", \"VLCE\", \"UTM_\" + str(zone) + \"S\", \"HMM\", \"LC_Class_HMM_\" + str(zone) + \"S_\" + str(year) + \".dat\") for zone in zones]\n",
    "        \n",
    "        nodata_value = 0\n",
    "        \n",
    "    if variable in utm_variables:\n",
    "        rasters = [os.path.join(\"H:\\\\\", \"utm\", \"UTM_\" + str(zone) + \"S\", \"Change_attribution_logic_rules\", \n",
    "                                variable + \"_UTM_\" + str(zone) + \"S_\" + str(year) + \".tif\") for zone in zones]\n",
    "        \n",
    "        nodata_value = 65535\n",
    "        \n",
    "    \n",
    "    masks = [os.path.join(\"..\", \"data\", \"non_overlapping_masks\", \"UTM_\" + str(zone) + \"S_mask.shp\") for zone in zones]\n",
    "    \n",
    "    map_inputs = [(rasters[i], masks[i]) for i in range(0, len(rasters))]\n",
    "    \n",
    "    print(\"Parallel processing raster clips\")\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        with Pool() as pool:\n",
    "            clipped_rasters = pool.starmap(clip_by_utm_zone, map_inputs)\n",
    "\n",
    "    warped_save_location = os.path.join(\"H:\\\\\", \"Merged\", variable, \"BC-\" + variable + \"-\" + str(year) + \".tif\")\n",
    "    warp_options = gdal.WarpOptions(format = \"GTiff\",\n",
    "                      dstSRS = \"EPSG:3005\", \n",
    "                      xRes = 30, \n",
    "                      yRes = 30,\n",
    "                      resampleAlg = \"near\",\n",
    "                      srcNodata = nodata_value,\n",
    "                      cutlineDSName = mask,\n",
    "                      cropToCutline = True\n",
    "                                   )\n",
    "\n",
    "    print(\"Warping Together\")\n",
    "    \n",
    "    gdal.Warp(warped_save_location, clipped_rasters, options = warp_options)\n",
    "    \n",
    "    clear_output(True)\n",
    "    \n",
    "    num_done += 1\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greatest Change Year and Attribution - For single temporal layer (no year field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcy_variables = [\"Greatest_Change_Year\", \"Change_Attribution\"]\n",
    "\n",
    "num_total = len(gcy_variables)\n",
    "\n",
    "\n",
    "num_done = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to warp fully: 637.6040256023407\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "mask = os.path.join(\"..\", \"data\", \"shapefiles\", \"bc_convex.shp\")\n",
    "\n",
    "for variable in gcy_variables[num_done - 1:]:\n",
    "    start_time = time.time()\n",
    "    print(str(num_done), \"/\", str(num_total))\n",
    "    print(variable)\n",
    "    \n",
    "    if variable == \"Greatest_Change_Year\":\n",
    "        rasters = [os.path.join(\"H:\\\\\", \"utm\", \"UTM_\" + str(zone) + \"S\", \"Results\", \"Change_metrics\",\n",
    "                                \"SRef_\" + str(zone) + \"S_\" + variable + \".dat\") for zone in zones]\n",
    "        nodata_value = 0\n",
    "    if variable == \"Change_Attribution\":\n",
    "        rasters = [os.path.join(\"H:\\\\\", \"utm\", \"UTM_\" + str(zone) + \"S\", \"Results\", \"Change_attribution\", \"Attribution_UTM\" + str(zone) + \"S_v2\" + \".dat\") for zone in zones] \n",
    "        nodata_value = 0\n",
    "        \n",
    "    masks = [os.path.join(\"..\", \"data\", \"non_overlapping_masks\", \"UTM_\" + str(zone) + \"S_mask.shp\") for zone in zones]\n",
    "    \n",
    "    map_inputs = [(rasters[i], masks[i]) for i in range(0, len(rasters))]\n",
    "    \n",
    "    print(\"Parallel processing raster clips\")\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        with Pool() as pool:\n",
    "            clipped_rasters = pool.starmap(clip_by_utm_zone, map_inputs)\n",
    "\n",
    "    warped_save_location = os.path.join(\"H:\\\\\", \"Merged\", variable, \"BC-\" + variable + \".tif\")\n",
    "    warp_options = gdal.WarpOptions(format = \"GTiff\",\n",
    "                      dstSRS = \"EPSG:3005\", \n",
    "                      xRes = 30, \n",
    "                      yRes = 30,\n",
    "                      resampleAlg = \"near\",\n",
    "                      srcNodata = nodata_value,\n",
    "                      cutlineDSName = mask,\n",
    "                      cropToCutline = True\n",
    "                                   )\n",
    "    print(\"Time to start warp:\", time.time() - start_time)\n",
    "    print(\"Warping Together\")\n",
    "    \n",
    "    gdal.Warp(warped_save_location, clipped_rasters, options = warp_options)\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Time to warp fully:\", time.time() - start_time)\n",
    "    \n",
    "    num_done += 1\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
